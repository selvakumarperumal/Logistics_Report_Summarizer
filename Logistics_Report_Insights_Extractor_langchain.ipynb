{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c323076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader, Docx2txtLoader\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"./.env\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d990ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Any\n",
    "\n",
    "def read_file(file_path: str) -> List[Any]:\n",
    "    \"\"\"\n",
    "    Read a file and return its content using appropriate LangChain document loader.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the file to be read\n",
    "        \n",
    "    Returns:\n",
    "        List[Any]: List of documents loaded from the file\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: If the file doesn't exist\n",
    "        ValueError: If the file type is not supported\n",
    "    \"\"\"\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "    \n",
    "    # Get file extension\n",
    "    file_extension = os.path.splitext(file_path)[1].lower()\n",
    "    \n",
    "    # Choose appropriate loader based on file extension\n",
    "    if file_extension == '.pdf':\n",
    "        loader = PyPDFLoader(file_path)\n",
    "    elif file_extension == '.txt':\n",
    "        loader = TextLoader(file_path)\n",
    "    elif file_extension in ['.docx', '.doc']:\n",
    "        loader = Docx2txtLoader(file_path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {file_extension}\")\n",
    "    \n",
    "    # Load and return documents\n",
    "    try:\n",
    "        documents = loader.load()\n",
    "        return documents\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error loading file: {str(e)}\")\n",
    "\n",
    "# Example usage function\n",
    "def read_and_display_content(file_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Read a file and display its content.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the file to be read\n",
    "    \"\"\"\n",
    "    try:\n",
    "        documents = read_file(file_path)\n",
    "        print(f\"Successfully loaded {len(documents)} document(s) from: {file_path}\")\n",
    "        \n",
    "        return documents\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32f477b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=10000,\n",
    "    chunk_overlap=500\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "583a0d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mistralai.chat_models import ChatMistralAI\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "chat_model = ChatMistralAI(\n",
    "    model_name=\"mistral-small-latest\",\n",
    "    temperature=0.7,\n",
    "    api_key=MISTRAL_API_KEY\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2655e7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt template created successfully!\n",
      "Template messages: 2\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\"You are a helpful assistant that helps to extract report from logistics data.\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"\"\"\n",
    "                                            Please extract the key informations from the following logistics report. In defined output format.\n",
    "                                            If any of the key information is missing, fill in with \"N/A\"\n",
    "                                            -Key Informations:{logistics_report}\n",
    "                                            -output_format:\n",
    "                                             \n",
    "                                            `json\n",
    "                                            {{\n",
    "                                             delivery_time: list[str]\n",
    "                                             delays: list[str]\n",
    "                                             route_issues: list[str]\n",
    "                                            }}\n",
    "                                             \n",
    "                                            {error_context}\n",
    "                                            \"\"\")\n",
    "])\n",
    "\n",
    "print(\"Prompt template created successfully!\")\n",
    "print(f\"Template messages: {len(prompt_template.messages)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e8c1b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "class SummaryResponse(BaseModel):\n",
    "    delivery_time: list[str] = Field(default_factory=list)\n",
    "    delays: list[str] = Field(default_factory=list)\n",
    "    route_issues: list[str] = Field(default_factory=list)\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=SummaryResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3ea906a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lcel = prompt_template | chat_model | output_parser\n",
    "\n",
    "def chain_with_retry(logistics_report : str, attempts: int = 3):\n",
    "\n",
    "    error_context = \"\"\n",
    "\n",
    "    for attempt in range(attempts):\n",
    "\n",
    "        try:\n",
    "            input_data = {\n",
    "                \"logistics_report\": logistics_report,\n",
    "                \"error_context\": error_context\n",
    "            }\n",
    "            result = lcel.invoke(input_data)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            error_context = \"Previous attempts failed with error: \" + str(e)\n",
    "            print(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "            if attempt == attempts - 1:\n",
    "                raise Exception(\"All attempts to process the logistics report have failed.\"+str(e))\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efd36ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain_with_retry(logistics_report=\"\"\"Truck 204 departed Bangalore at 10:30 AM.\n",
    "Delay of 3 hours due to highway construction near Hosur.\n",
    "Consignment #556 delivered in Chennai at 4:00 PM.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583f9a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backend_api (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
